install.packages("data.table")
library(data.table)
DT <- fread(fileUrl)
DT <- fread(fileUrl, method="curl")
?fread
DT <- fread("./data/acs_06.csv")
download.file(fileUrl, destfile = "./data/acs_06.csv", method = "curl")
DT <- fread("./data/acs_06.csv")
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time({rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]})
system.time({mean(DT$pwgtp15,by=DT$SEX)})
mean(DT$pwgtp15,by=DT$SEX)
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time({rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]})
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
?mean
split(DT$pwgtp15, DT$SEX)
str(split(DT$pwgtp15, DT$SEX))
sapply(split(DT$pwgtp15, DT$SEX), mean)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT[,mean(pwgtp15),by=SEX]
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15, DT$SEX), mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
quit()
install.packages("RMySQL")
q()
Sys.getenv("PATH")
Sys.getenv('MYSQL_HOME')
Sys.getenv("PATH")
install.packages("DBI")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
quit()
library(httr)
install.package("httpuv")
install.packages("httpuv")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "ced1b58b3b60aaa81dfa", secret = "189d46e4bef5783d48ca40f977dac3924d4e42bd")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
install.packages("jsonlite")
content(req)
library(JSON)
library(jsonlite)
clean_content <- fromJSON(toJSON(content(req)))
clean_content
names(clean_content)
clean_content$id
clean_content$name
clean_content$name == "datasharing"
clean_content[clean_content$name == "datasharing",]
names(clean_content)
clean_content[clean_content$name == "datasharing",]$created_at
install.packages("sqldf")
library(XML)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
html <- htmlTreeParse(url, useInternalNodes=T)
getcwd()
cwd()
getwd()
download.file(url, destfile = "./data/acs_data.csv", method="curl")
acs <- read.csv("./data/acs_data.csv")
names(acs)
sqldf("select pwgtp1 from acs")
library(sqldf)
sqldf("select pwgtp1 from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
pwgtp1_50 <- sqldf("select pwgtp1 from acs where AGEP < 50")
length(pwgtp1_50)
dim(pwgtp1_50)
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
dim(
sqldf("select distinct AGEP from acs"))
dim(unique(acs$AGEP))
length(unique(acs$AGEP))
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readlines(con)
htmlCode <- readLines(con)
close(con)
htmlCode
nchar(htmlCode[10,])
nchar(htmlCode[10])
nchar(htmlCode[10,20,30,100])
for (i in c(10,20,30,100)) {}
for (i in c(10,20,30,100)) {print(i)]}
for (i in c(10,20,30,100)) {print(i)]
for (i in c(10,20,30,100)) {print(i)}
for (i in c(10,20,30,100)) {nchar(htmlCode[i])}
for (i in c(10,20,30,100)) {print(nchar(htmlCode[i]))}
?read.fwf
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
nasa_data <- read.fwf(con)
nasa_data <- read.fwf(con, widths = c(10,9,4,9,4,9,4,9,4), header = T)
close(con)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), header = T)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), header = T, sep = "")
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), header = T, sep = " ")
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4))
nasa_df <- data.frame(nasa_data)
names(nasa_df)
nasa_data[1,]
nasa_data[2,]
colnames(nasa_data) <- nasa_data[1,]
nasa_data
names(nasa_data)
colnames(nasa_data)
nasa_data[1,]
names(nasa_data) <- nasa_data[1,]
names(nasa_data)
nasa_df <- data.frame(nasa_data, row.names = nasa_data[1,])
nasa_df <- data.frame(nasa_data, col.names = nasa_data[1,])
nasa_df <- data.frame(nasa_data, column.names = nasa_data[1,])
names(nasa_df)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4))
col.names(nasa_data)
type(nasa_data)
class(nasa_data)
nasa_data <- data.frame(nasa_data, col.names = nasa_data[1,])
names(nasa_df)
names(nasa_data)
nasa_data[1,]
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4))
sum(nasa_data[,5])
sum(as.numeric(nasa_data[,5]), na.rm=T)
nasa_data[51,]
nasa_data[51,1]
nasa_data[51,2]
nasa_data[51,3]
nasa_data[51,4]
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("Date","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"))
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("Date","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), header = T)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("Date","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), header = T, sep = "")
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("Date","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), header = T, sep = " ")
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("Date","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), skip=1)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("char","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), skip=1)
nasa_data <- read.fwf("./data/getdata-wksst8110.for", widths = c(10,9,4,9,4,9,4,9,4), colClasses = c("character","numeric", "numeric","numeric","numeric","numeric","numeric","numeric","numeric"), skip=1)
nasa_data
sum(nasa_data[,4])
sum(nasa_data[,1])
sum(nasa_data[,5])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile="./data/getting_data.zip", method="curl")
unzip("./data/getting_data.zip")
ls()
dir()
dir(./data/)
dir("./data/")
dir("./data/")
quit()
source('~/coursera/datasciencecoursera/run_analysis.R', echo=TRUE)
test_set <- cbind(test_data, train_subject, train_activity)
test_set <- cbind(test_data, test_subject, test_activity)
train_data_filt <- train_data[,mean_std_cols]
train_subject <- read.table("data/UCI_HAR_Dataset/train/subject_train.txt",
col.name = "subject")
train_activity <- read.table("data/UCI_HAR_Dataset//train//y_train.txt",
col.name = "activity")
train_set <- cbind(train_data_filt, train_subject, train_activity)
# Read in test data, select mean and std columns, and cbind subject and activity.
test_data <- read.table("data/UCI_HAR_Dataset/test//X_test.txt", col.names = col_names)
test_data_filt <- train_data[,mean_std_cols]
test_subject <- read.table("data/UCI_HAR_Dataset/test//subject_test.txt",
col.name = "subject")
test_activity <- read.table("data/UCI_HAR_Dataset//test//y_test.txt",
col.name = "activity")
test_set <- cbind(test_data_filt, test_subject, test_activity)
source('~/coursera/datasciencecoursera/run_analysis.R', echo=TRUE)
test_data <- read.table("data/UCI_HAR_Dataset/test/X_test.txt", col.names = col_names)
test_data_filt <- test_data[,mean_std_cols]
test_subject <- read.table("data/UCI_HAR_Dataset/test/subject_test.txt",
col.name = "subject")
test_activity <- read.table("data/UCI_HAR_Dataset/test/y_test.txt",
col.name = "activity")
test_set <- cbind(test_data_filt, test_subject, test_activity)
data_set <- rbind(train_set, test_set)
activity_names$activityCode == "2"
activity_names[activity_names$activityCode == "2"]
activity_names[activity_names$activityCode == "2",]
activity_names[activity_names$activityCode == "2",]$activityName
activity_names
activity_names <- read.table("data/UCI_HAR_Dataset//activity_labels.txt",
col.names = c("activityCode", "activityName"))
activities <- activity_names$activityCode
names(activities) <- activity_names$activityName
activities
activities["1"]
activities[1]
activities[3]
activities[activity_names$activityName]
activities <- vector(mode="list", length = nrow(activity_names))
activities
activity_df <- read.table("data/UCI_HAR_Dataset//activity_labels.txt",
col.names = c("activityCode", "activityName"))
activities
activities <- activity_df$activityCode
names(activities) <- activity_df$activityName
activities
activities[[4]]
activities[4
]
activities <- vector(mode="list", length = nrow(activity_names))
activities <- activity_df$activityName
names(activities) <- activity_df$activityCode
activities
activities["4"]
head(data_set$activity)
activities[head(data_set$activity)]
data_set_backup <- data_Set
data_set_backup <- data_set
data_set$activity <- activities[data_set$activity]
head(data_set$activity)
source('~/coursera/datasciencecoursera/run_analysis.R', echo=TRUE)
levels(data_set$subject)
levels(data_set$subjects)
names(data_set)
levels(data_set$subject)
summary(data_set$subject)
levels(as.factor(data_set$subject))
data_set[data_set$subject == "4"]
data_set[,data_set$subject == 4]
data_set[,data_set$subject == "4]
data_set[,data_set$subject == "4"]
data_set[[data_set$subject == "4"]]
data_set$subject == "4"
summary(data_set$subject == "4")
data_set[data_set$subject == "4",]
data_set[data_set$subject == "4" && data_set$activity == "WALKING",]
data_set[(data_set$subject == "4" && data_set$activity == "WALKING"),]
data_set$subject == "4" && data_set$activity == "WALKING"
data_set$subject == "4" & data_set$activity == "WALKING"
data_set[(data_set$subject == "4" & data_set$activity == "WALKING"),]
nrow(data_set[(data_set$subject == "4" & data_set$activity == "WALKING"),])
?data.frame
for (x in names(activities)) print (names)
for (x in names(activities)) print (x)
for (x in activities) print (x)
sapply(data_set, mean)
aggregate(data_set, c("subject", "activity"))
aggregate(data_set, c("subject", "activity"), mean)
class(c("hi","foo"))
c("hi","foo")
list("hi","foo")
aggregate(data_set, list("subject", "activity"), mean)
testDF <- data.frame(v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),
v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99) )
by1 <- c("red", "blue", 1, 2, NA, "big", 1, 2, "red", 1, NA, 12)
by2 <- c("wet", "dry", 99, 95, NA, "damp", 95, 99, "red", 99, NA, NA)
aggregate(x = testDF, by = list(by1, by2), FUN = "mean")
aggregate(x = testDF, by = by1, FUN = "mean")
aggregate(x = testDF, by = list(by1), FUN = "mean")
aggregate(data_set, by = list(data_set$subject, data_set$activity), FUN = "mean")
levels(data_set$activity)
summary(data_set)
summary(data_set$activity)
agg_data_set = aggregate(data_set, by = list(data_set$subject, data_set$activity), FUN = "mean")
data_set$subject = as.factor(data_set$subject)
agg_data_set = aggregate(data_set, by = list(data_set$subject, data_set$activity), FUN = "mean")
aggregate(data_set, by = list(data_set$subject, data_set$activity), FUN = "mean")
warnings()
aggregate(data_set, by = list(data_set$subject, data_set$activity), FUN = "mean", na.action = na.omit)
remove(agg_data_set$subject)
remove(agg_data_set, agg_data_set$subject)
agg_test_data_filt <- aggregate(test_data_filt, by = list(test_subject, test_activity), FUN = "mean")
by = list(test_subject, test_activity)
rm(by)
list(test_subject, test_activity)
dim(list(test_subject, test_activity))
nrow(list(test_subject, test_activity))
by3 <- list(test_subject, test_activity)
by3 <- as.character(list(test_subject, test_activity))
by3 <- list(as.character(test_subject), as.character(test_activity))
agg_test_data_filt <- aggregate(test_data_filt, by = by3, FUN = "mean")
test_subject_char <- as.character(test_subject)
agg_test_data_filt <- aggregate(test_data_filt, by = test_subject_char, FUN = "mean")
agg_test_data_filt <- aggregate(test_data_filt, by = list(test_subject_char), FUN = "mean")
list(test_subject_char)
class(test_subject)
agg_test_data_filt <- aggregate(test_data_filt, by = list(test_subject), FUN = "mean")
summary(test_subject_char)
summary(list(test_subject))
as.list(test_subject)
agg_test_data_filt <- aggregate(test_data_filt, by = as.list(test_subject), FUN = "mean")
head(agg_test_data_filt)
agg_test_data_filt <- aggregate(test_data_filt, by = as.list(c(test_subject, test_activity), FUN = "mean")
)
agg_test_data_filt <- aggregate(test_data_filt, by = as.list(c(test_subject, test_activity), FUN = "mean")
)
agg_test_data_filt <- aggregate(test_data_filt, by = as.list(c(test_subject, test_activity)), FUN = "mean")
head(agg_test_data_filt)
write.csv(data_set, file = "data/UCI_HAR_Dataset/data_set.csv")
write.csv(agg_data_set, file = "data/UCI_HAR_Dataset/agg_data_set.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", file = "data/idaho.csv", method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", dest = "data/idaho.csv", method = "curl")
idaho <- read.csv("data/idaho.csv")
names(idaho)
summary(idaho$ACR)
summary(idaho$ACR == 3)
summary(idaho["ACR" == 3])
idaho["ACR" == 3]
idaho["ACR" == 3,]
idaho[,"ACR" == 3]
summary(idaho$ACR == 3)
summary(idaho$ACR == 3 & idaho$AGS == 6)
agricultureLogical <- idaho$ACR == 3 & idaho$AGS == 6
which(agricultureLogical)
library(jpeg)
install.packages("jpeg")
library(jpeg)
?read.jpeg
?jpeg
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", dest = "data/jeff.jpg", method = "curl")
jeff <- jpeg("data/jeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", dest = "data/jeff.jpg", method = "curl")
readJPEG("data/jeff.jpg")
jeff <- readJPEG("data/jeff.jpg")
jeff <- readJPEG("data/jeff.jpg", native = TRUE)
summary(jeff)
?quantile
quantile(jeff, probs = seq(.3, .8))
quantile(jeff, probs = seq(.8))
quantile(jeff, probs = seq(0.8))
quantile(jeff, probs = c(.3, .8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", dest = "data/GDP.csv", method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", dest = "data/edu.csv", method = "curl")
gdp <- read.csv("data/GDP.csv")
edu <- read.csv("data/edu.csv")
?cbind
names(gdp)
names(edu)
?read.csv
gdp <- read.csv("data/GDP.csv")
names(gdp)
gdp <- read.csv("data/GDP.csv")
edu <- read.csv("data/edu.csv")
names(gdp)
names(edu)
countries <- merge(gdp, edu, by = CountryCode)
countries <- merge(gdp, edu, by = "CountryCode")
?sort
?order
countries[with(countries, order(CountryCode))]
countries[with(countries, order("CountryCode"))]
names(countries)
countries[with(countries, order("GCP2012"))]
countries[with(countries, order("GDP2012"))]
countries[with(countries, order("Ranking"))]
countries[with(countries, order(countries$Ranking))]
countries <- merge(gdp, edu, by = "CountryCode")
countries
countries[with(countries, order(countries$Ranking)),]
countries[with(countries, order(countries$Ranking)),]$CountryCode
countries[with(countries, order(countries$Ranking, decreasing = TRUE)),]$CountryCode
countries[with(countries, order(countries$Ranking, decreasing = TRUE)),]$CountryCode[[13]]
countries[with(countries, order(countries$Ranking, decreasing = TRUE)),]$LongName[[13]]
countries[with(countries, order(countries$Ranking, decreasing = TRUE)),]$Short.Name[[13]]
names(countries)
summary(countries[[12]])
countries$Income.Group == "High income: nonOECD"
mean(countries[countries$Income.Group == "High income: nonOECD"]$Ranking)
mean(countries[countries$Income.Group == "High income: nonOECD",]$Ranking)
mean(countries[countries$Income.Group == "High income: OECD",]$Ranking)
?quantile
quantile(countries, probs = c(0, .2, .4, .6, .8))
quantile(countries, probs = c(0, .2, .4, .6, .8), na.rm = TRUE)
quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8), na.rm = TRUE)
seq(0,1,.2)
cut(countries$Ranking, breaks = quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8), na.rm = TRUE))
cut(countries$Ranking, breaks = quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8), na.rm = TRUE), na.rm = true)
cut(countries$Ranking, breaks = quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8), na.rm = TRUE))
cut(countries$Ranking, breaks = quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8, 1), na.rm = TRUE))
countries$Quintile <- cut(countries$Ranking, breaks = quantile(countries$Ranking, probs = c(0, .2, .4, .6, .8, 1), na.rm = TRUE))
?table
table(countries$Quintile ~ countries$Income.Group)
datatable
table(countries$Quintile, countries$Income.Group)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", dest = "data/idaho2.csv", method = "curl")
idaho2 <- read.csv("data/idaho2.csv")
strsplit(names(idaho2))
strsplit(names(idaho2), split = "wgtp")
strsplit(names(idaho2), split = "wgtp")[[123]]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", dest = "data/GDP.csv", method = "curl")
?read.csv
gdp <- read.csv("data/GDP.csv", skip = 6)
head(gdp)
gdp <- read.csv("data/GDP.csv", skip = 5)
head(gdp)
gdp <- read.csv("data/GDP.csv")
head(gdp)
gdp <- read.csv("data/GDP.csv", skip = 4)
head(gdp)
head(as.numeric(gdp$X.4))
as.numeric(gdp$X.4)
gdp$X.4
gdp <- read.csv("data/GDP.csv", skip = 4, nrows = 190)
gdp$X.4
gdp <- read.csv("data/GDP.csv", skip = 4, nrows = 191)
gdp$X.4
gdp <- read.csv("data/GDP.csv", skip = 4, nrows = 192)
gdp$X.4
gdp <- read.csv("data/GDP.csv", skip = 4, nrows = 191)
gdp <- read.csv("data/GDP.csv", skip = 4, nrows = 190)
as.numeric(gdp$X.4)
gsub(",","",gdp$X.4)
as.numeric(gsub(",","",gdp$X.4))
gdp$X.4 <- as.numeric(gsub(",","",gdp$X.4))
mean(gdp$X.4)
names(gdp)
head(gdp)
countryNames <- gdp$X.3
grep("^United", countryNames)
countryNames
?grep
grep("^United", countryNames)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", dest = "data/fedstats.csv", method = "curl")
head(gdp)
names(gdp)
names(gdp) <- c("countryCode","rank", "X.2", "countryName", "GDP")
names(gdp)
names(gdp) <- c("countryCode","rank", NA, "countryName", "GDP")
names(gdp)
fedstats <- read.csv("data/fedstats.csv")
names(fedstats)
countries <- merge(gdp, fedstats, by.x = countryCode, by.y = CountryCode)
countries <- merge(gdp, fedstats, by.x = CountryCode, by.y = CountryCode)
countries <- merge(gdp, fedstats, by.x = CountryCode, by.y = countryCode)
countries <- merge(gdp, fedstats, by.x = countryCode, by.y = countryCode)
names(gdp)
countries <- merge(gdp, fedstats, by.x = "countryCode", by.y = "countryCode")
countries <- merge(gdp, fedstats, by.x = "countryCode", by.y = "CountryCode")
?merge
head(countries)
grep("June", countries$Special.Notes)
?count
??count
?len
?length
length(grep("June", countries$Special.Notes))
countries[grep("June", countries$Special.Notes)]
countries[grep("June", countries$Special.Notes),]
countries[grep("June", countries$Special.Notes),]$Special.Notes
length(grep("Fiscal year end: June", countries$Special.Notes))
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
?index
grep("^2012", sampleTimes)
length(grep("^2012", sampleTimes))
names(amzn)
weekdays(sampleTimes)
sampleTimes[grep("^2012", sampleTimes),]
sampleTimes[grep("^2012", sampleTimes)]
weekday(sampleTimes[grep("^2012", sampleTimes)])
weekdays(sampleTimes[grep("^2012", sampleTimes)])
weekdays(sampleTimes[grep("^2012", sampleTimes)]) == "Monday"
summary(weekdays(sampleTimes[grep("^2012", sampleTimes)]) == "Monday")
?match
x <- rnorm(100)
hist(x)
y <- rnorm(100)
plot(x, y)
plot(x, y, pch = 20)
plot(x, y, pch = 19)
plot(x, y, pch = 2)
plot(x, y, pch = 3)
plot(x, y, pch = 4)
example(points)
plot(x, y)
x <- rnorm(100)
y <- rnorm(100)
plot(x, y)
plot(x, y, pch = 20)
title("Scatterplot")
text(-2, -2, "Label")
legent("topleft", legend = "Data", pch = 20)
legend("topleft", legend = "Data", pch = 20)
fit <- lm(y~x)
abline(fit)
abline(fit, lwd = 3, col = "blue")
plot(x, y, xlab = "Weight", ylab = "Height", main = "Scatterplot", pch = 20)
legend("topright", legend = "Data", pch = 20)
abline(fit, lwd = 3, col = "red")
z <- rpois(100, 2)
par(mfrow = c(2, 1))
plot(x, y, pch = 20)
library(knitr)
setwd("../RepData_PeerAssessment1/")
knit2html("PA1_template.Rmd")
